{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f6183-e446-4794-adba-dc3f9f1eaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs includes whole 1-1 part and 1-2-1, 1-2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005a898a-93ff-40d5-a0d7-1706f50ef302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb  9 00:26:44 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    23W / 250W |    126MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    24W / 250W |     45MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4527      G   /usr/libexec/Xorg                  22MiB |\n",
      "|    0   N/A  N/A      5483      G   /usr/libexec/Xorg                  63MiB |\n",
      "|    0   N/A  N/A      5634      G   /usr/bin/gnome-shell               38MiB |\n",
      "|    1   N/A  N/A      4527      G   /usr/libexec/Xorg                  22MiB |\n",
      "|    1   N/A  N/A      5483      G   /usr/libexec/Xorg                  22MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538b8421-2814-40cc-9836-6e12a2ad4b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision==0.9.1 in ./.local/lib/python3.9/site-packages (0.9.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from torchvision==0.9.1) (9.0.1)\n",
      "Requirement already satisfied: numpy in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from torchvision==0.9.1) (1.21.5)\n",
      "Requirement already satisfied: torch==1.8.1 in ./.local/lib/python3.9/site-packages (from torchvision==0.9.1) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (from torch==1.8.1->torchvision==0.9.1) (4.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages (4.64.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.9.1\n",
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35437ac4-7371-47fc-b857-1e371b16b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ebbc0b1-8600-4466-89e3-1b718b79aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7498f1b3-a615-4010-b1fb-60b303305949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "debug 2.....\n"
     ]
    }
   ],
   "source": [
    "nw = 0\n",
    "bs = 64\n",
    "vsize = 0.2\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "td = datasets.CIFAR10('data', train=True, download=True, transform=transform)\n",
    "testd = datasets.CIFAR10('data', train=False, download=True, transform=transform)\n",
    "\n",
    "tl = len(td)\n",
    "i = list(range(tl))\n",
    "np.random.shuffle(i)\n",
    "split = int(np.floor(vsize * tl))\n",
    "ti, vi = i[split:], i[:split]\n",
    "\n",
    "training_data = SubsetRandomSampler(ti)\n",
    "validation_data = SubsetRandomSampler(vi)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(td, batch_size=bs,\n",
    "    sampler=training_data, num_workers=nw)\n",
    "valid_loader = torch.utils.data.DataLoader(td, batch_size=bs, \n",
    "    sampler=validation_data, num_workers=nw)\n",
    "test_loader = torch.utils.data.DataLoader(testd, batch_size=bs, \n",
    "    num_workers=nw)\n",
    "\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print('debug 2.....')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19ea19e-4532-477f-9f07-52d68bace27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(p=.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # flattening\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        # fully connected layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96fc4f2-cd11-4acc-9be2-c665795a59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model1 = Net()\n",
    "if train_on_gpu:\n",
    "  model1.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=0.01, weight_decay = 0.005, momentum = 0.9) \n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89422b96-5e6e-4967-80d8-85cce4cda4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.601427 \tValidation Loss: 0.145250\n",
      "Validation loss decreased (inf --> 0.145250).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.606379 \tValidation Loss: 0.143673\n",
      "Validation loss decreased (0.145250 --> 0.143673).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.602927 \tValidation Loss: 0.149000\n",
      "Epoch: 4 \tTraining Loss: 0.605797 \tValidation Loss: 0.148678\n",
      "Epoch: 5 \tTraining Loss: 0.608253 \tValidation Loss: 0.150658\n",
      "Epoch: 6 \tTraining Loss: 0.610592 \tValidation Loss: 0.146314\n",
      "Epoch: 7 \tTraining Loss: 0.602968 \tValidation Loss: 0.146054\n",
      "Epoch: 8 \tTraining Loss: 0.600615 \tValidation Loss: 0.159468\n",
      "Epoch: 9 \tTraining Loss: 0.609792 \tValidation Loss: 0.143969\n",
      "Epoch: 10 \tTraining Loss: 0.604620 \tValidation Loss: 0.158460\n",
      "Epoch: 11 \tTraining Loss: 0.597011 \tValidation Loss: 0.149902\n",
      "Epoch: 12 \tTraining Loss: 0.608050 \tValidation Loss: 0.145405\n",
      "Epoch: 13 \tTraining Loss: 0.595591 \tValidation Loss: 0.155291\n",
      "Epoch: 14 \tTraining Loss: 0.603008 \tValidation Loss: 0.151900\n",
      "Epoch: 15 \tTraining Loss: 0.598875 \tValidation Loss: 0.151467\n",
      "Epoch: 16 \tTraining Loss: 0.605299 \tValidation Loss: 0.145625\n",
      "Epoch: 17 \tTraining Loss: 0.602428 \tValidation Loss: 0.161242\n",
      "Epoch: 18 \tTraining Loss: 0.604698 \tValidation Loss: 0.163041\n",
      "Epoch: 19 \tTraining Loss: 0.607308 \tValidation Loss: 0.147584\n",
      "Epoch: 20 \tTraining Loss: 0.597814 \tValidation Loss: 0.146574\n",
      "Epoch: 1 \tTraining Loss: 0.600725 \tValidation Loss: 0.156305\n",
      "Validation loss decreased (inf --> 0.156305).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.599670 \tValidation Loss: 0.173920\n",
      "Epoch: 3 \tTraining Loss: 0.601386 \tValidation Loss: 0.151913\n",
      "Validation loss decreased (0.156305 --> 0.151913).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.601416 \tValidation Loss: 0.150956\n",
      "Validation loss decreased (0.151913 --> 0.150956).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.600808 \tValidation Loss: 0.151695\n",
      "Epoch: 6 \tTraining Loss: 0.608892 \tValidation Loss: 0.169529\n",
      "Epoch: 7 \tTraining Loss: 0.604937 \tValidation Loss: 0.151115\n",
      "Epoch: 8 \tTraining Loss: 0.604591 \tValidation Loss: 0.143862\n",
      "Validation loss decreased (0.150956 --> 0.143862).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.591662 \tValidation Loss: 0.152536\n",
      "Epoch: 10 \tTraining Loss: 0.603981 \tValidation Loss: 0.143202\n",
      "Validation loss decreased (0.143862 --> 0.143202).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.601729 \tValidation Loss: 0.162538\n",
      "Epoch: 12 \tTraining Loss: 0.600079 \tValidation Loss: 0.152709\n",
      "Epoch: 13 \tTraining Loss: 0.601508 \tValidation Loss: 0.148634\n",
      "Epoch: 14 \tTraining Loss: 0.600431 \tValidation Loss: 0.149752\n",
      "Epoch: 15 \tTraining Loss: 0.600481 \tValidation Loss: 0.154951\n",
      "Epoch: 16 \tTraining Loss: 0.598811 \tValidation Loss: 0.158080\n",
      "Epoch: 17 \tTraining Loss: 0.599568 \tValidation Loss: 0.157822\n",
      "Epoch: 18 \tTraining Loss: 0.603422 \tValidation Loss: 0.150350\n",
      "Epoch: 19 \tTraining Loss: 0.601504 \tValidation Loss: 0.149918\n",
      "Epoch: 20 \tTraining Loss: 0.608422 \tValidation Loss: 0.148422\n",
      "Epoch: 1 \tTraining Loss: 0.605705 \tValidation Loss: 0.147756\n",
      "Validation loss decreased (inf --> 0.147756).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.602751 \tValidation Loss: 0.154469\n",
      "Epoch: 3 \tTraining Loss: 0.603001 \tValidation Loss: 0.144938\n",
      "Validation loss decreased (0.147756 --> 0.144938).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.596494 \tValidation Loss: 0.142969\n",
      "Validation loss decreased (0.144938 --> 0.142969).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.595174 \tValidation Loss: 0.154019\n",
      "Epoch: 6 \tTraining Loss: 0.594690 \tValidation Loss: 0.149097\n",
      "Epoch: 7 \tTraining Loss: 0.602878 \tValidation Loss: 0.142522\n",
      "Validation loss decreased (0.142969 --> 0.142522).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.607299 \tValidation Loss: 0.147990\n",
      "Epoch: 9 \tTraining Loss: 0.606025 \tValidation Loss: 0.150309\n",
      "Epoch: 10 \tTraining Loss: 0.600070 \tValidation Loss: 0.152389\n",
      "Epoch: 11 \tTraining Loss: 0.602614 \tValidation Loss: 0.144434\n",
      "Epoch: 12 \tTraining Loss: 0.592776 \tValidation Loss: 0.155339\n",
      "Epoch: 13 \tTraining Loss: 0.596729 \tValidation Loss: 0.144182\n",
      "Epoch: 14 \tTraining Loss: 0.607952 \tValidation Loss: 0.149778\n",
      "Epoch: 15 \tTraining Loss: 0.602431 \tValidation Loss: 0.151515\n",
      "Epoch: 16 \tTraining Loss: 0.606490 \tValidation Loss: 0.151148\n",
      "Epoch: 17 \tTraining Loss: 0.598342 \tValidation Loss: 0.150208\n",
      "Epoch: 18 \tTraining Loss: 0.602457 \tValidation Loss: 0.150157\n",
      "Epoch: 19 \tTraining Loss: 0.603007 \tValidation Loss: 0.150820\n",
      "Epoch: 20 \tTraining Loss: 0.597312 \tValidation Loss: 0.157700\n",
      "Epoch: 1 \tTraining Loss: 0.603405 \tValidation Loss: 0.169808\n",
      "Validation loss decreased (inf --> 0.169808).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.600946 \tValidation Loss: 0.150296\n",
      "Validation loss decreased (0.169808 --> 0.150296).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.599058 \tValidation Loss: 0.160328\n",
      "Epoch: 4 \tTraining Loss: 0.599171 \tValidation Loss: 0.147724\n",
      "Validation loss decreased (0.150296 --> 0.147724).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.603767 \tValidation Loss: 0.146661\n",
      "Validation loss decreased (0.147724 --> 0.146661).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.602049 \tValidation Loss: 0.152889\n",
      "Epoch: 7 \tTraining Loss: 0.596296 \tValidation Loss: 0.140896\n",
      "Validation loss decreased (0.146661 --> 0.140896).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.597651 \tValidation Loss: 0.149393\n",
      "Epoch: 9 \tTraining Loss: 0.603065 \tValidation Loss: 0.151669\n",
      "Epoch: 10 \tTraining Loss: 0.601171 \tValidation Loss: 0.163273\n",
      "Epoch: 11 \tTraining Loss: 0.604464 \tValidation Loss: 0.162065\n",
      "Epoch: 12 \tTraining Loss: 0.597683 \tValidation Loss: 0.146564\n",
      "Epoch: 13 \tTraining Loss: 0.605858 \tValidation Loss: 0.147686\n",
      "Epoch: 14 \tTraining Loss: 0.601186 \tValidation Loss: 0.155296\n",
      "Epoch: 15 \tTraining Loss: 0.599295 \tValidation Loss: 0.141973\n",
      "Epoch: 16 \tTraining Loss: 0.605152 \tValidation Loss: 0.157373\n",
      "Epoch: 17 \tTraining Loss: 0.596871 \tValidation Loss: 0.150569\n",
      "Epoch: 18 \tTraining Loss: 0.604250 \tValidation Loss: 0.165823\n",
      "Epoch: 19 \tTraining Loss: 0.603637 \tValidation Loss: 0.154256\n",
      "Epoch: 20 \tTraining Loss: 0.603426 \tValidation Loss: 0.141596\n",
      "Epoch: 1 \tTraining Loss: 0.600512 \tValidation Loss: 0.173013\n",
      "Validation loss decreased (inf --> 0.173013).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.601903 \tValidation Loss: 0.161030\n",
      "Validation loss decreased (0.173013 --> 0.161030).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.605438 \tValidation Loss: 0.153344\n",
      "Validation loss decreased (0.161030 --> 0.153344).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.603172 \tValidation Loss: 0.149201\n",
      "Validation loss decreased (0.153344 --> 0.149201).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.598981 \tValidation Loss: 0.151511\n",
      "Epoch: 6 \tTraining Loss: 0.597896 \tValidation Loss: 0.148383\n",
      "Validation loss decreased (0.149201 --> 0.148383).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.600673 \tValidation Loss: 0.143910\n",
      "Validation loss decreased (0.148383 --> 0.143910).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.600318 \tValidation Loss: 0.158568\n",
      "Epoch: 9 \tTraining Loss: 0.605033 \tValidation Loss: 0.149457\n",
      "Epoch: 10 \tTraining Loss: 0.596484 \tValidation Loss: 0.143591\n",
      "Validation loss decreased (0.143910 --> 0.143591).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.599218 \tValidation Loss: 0.151178\n",
      "Epoch: 12 \tTraining Loss: 0.594304 \tValidation Loss: 0.152945\n",
      "Epoch: 13 \tTraining Loss: 0.599270 \tValidation Loss: 0.148927\n",
      "Epoch: 14 \tTraining Loss: 0.605741 \tValidation Loss: 0.148464\n",
      "Epoch: 15 \tTraining Loss: 0.604245 \tValidation Loss: 0.147525\n",
      "Epoch: 16 \tTraining Loss: 0.602292 \tValidation Loss: 0.151331\n",
      "Epoch: 17 \tTraining Loss: 0.599092 \tValidation Loss: 0.148611\n",
      "Epoch: 18 \tTraining Loss: 0.594401 \tValidation Loss: 0.143553\n",
      "Validation loss decreased (0.143591 --> 0.143553).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.597342 \tValidation Loss: 0.147266\n",
      "Epoch: 20 \tTraining Loss: 0.596393 \tValidation Loss: 0.154647\n",
      "Epoch: 1 \tTraining Loss: 0.596816 \tValidation Loss: 0.150382\n",
      "Validation loss decreased (inf --> 0.150382).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.600313 \tValidation Loss: 0.146917\n",
      "Validation loss decreased (0.150382 --> 0.146917).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.605459 \tValidation Loss: 0.143030\n",
      "Validation loss decreased (0.146917 --> 0.143030).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.595819 \tValidation Loss: 0.144227\n",
      "Epoch: 5 \tTraining Loss: 0.596167 \tValidation Loss: 0.162180\n",
      "Epoch: 6 \tTraining Loss: 0.599467 \tValidation Loss: 0.153018\n",
      "Epoch: 7 \tTraining Loss: 0.595423 \tValidation Loss: 0.141769\n",
      "Validation loss decreased (0.143030 --> 0.141769).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.599853 \tValidation Loss: 0.143977\n",
      "Epoch: 9 \tTraining Loss: 0.600841 \tValidation Loss: 0.158046\n",
      "Epoch: 10 \tTraining Loss: 0.598693 \tValidation Loss: 0.149793\n",
      "Epoch: 11 \tTraining Loss: 0.596393 \tValidation Loss: 0.144085\n",
      "Epoch: 12 \tTraining Loss: 0.597368 \tValidation Loss: 0.154556\n",
      "Epoch: 13 \tTraining Loss: 0.598094 \tValidation Loss: 0.155028\n",
      "Epoch: 14 \tTraining Loss: 0.605043 \tValidation Loss: 0.152019\n",
      "Epoch: 15 \tTraining Loss: 0.600232 \tValidation Loss: 0.149982\n",
      "Epoch: 16 \tTraining Loss: 0.593444 \tValidation Loss: 0.144368\n",
      "Epoch: 17 \tTraining Loss: 0.605966 \tValidation Loss: 0.151881\n",
      "Epoch: 18 \tTraining Loss: 0.606786 \tValidation Loss: 0.147517\n",
      "Epoch: 19 \tTraining Loss: 0.595418 \tValidation Loss: 0.148031\n",
      "Epoch: 20 \tTraining Loss: 0.604101 \tValidation Loss: 0.148189\n",
      "Epoch: 1 \tTraining Loss: 0.594312 \tValidation Loss: 0.149646\n",
      "Validation loss decreased (inf --> 0.149646).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.601044 \tValidation Loss: 0.145046\n",
      "Validation loss decreased (0.149646 --> 0.145046).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.593895 \tValidation Loss: 0.169785\n",
      "Epoch: 4 \tTraining Loss: 0.606940 \tValidation Loss: 0.150383\n",
      "Epoch: 5 \tTraining Loss: 0.599005 \tValidation Loss: 0.154105\n",
      "Epoch: 6 \tTraining Loss: 0.593553 \tValidation Loss: 0.148641\n",
      "Epoch: 7 \tTraining Loss: 0.594318 \tValidation Loss: 0.143752\n",
      "Validation loss decreased (0.145046 --> 0.143752).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.592825 \tValidation Loss: 0.155021\n",
      "Epoch: 9 \tTraining Loss: 0.597163 \tValidation Loss: 0.151971\n",
      "Epoch: 10 \tTraining Loss: 0.598403 \tValidation Loss: 0.143177\n",
      "Validation loss decreased (0.143752 --> 0.143177).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.605371 \tValidation Loss: 0.143829\n",
      "Epoch: 12 \tTraining Loss: 0.598847 \tValidation Loss: 0.155432\n",
      "Epoch: 13 \tTraining Loss: 0.598440 \tValidation Loss: 0.156492\n",
      "Epoch: 14 \tTraining Loss: 0.600237 \tValidation Loss: 0.155335\n",
      "Epoch: 15 \tTraining Loss: 0.596655 \tValidation Loss: 0.148266\n",
      "Epoch: 16 \tTraining Loss: 0.598534 \tValidation Loss: 0.150231\n",
      "Epoch: 17 \tTraining Loss: 0.598265 \tValidation Loss: 0.141153\n",
      "Validation loss decreased (0.143177 --> 0.141153).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.600515 \tValidation Loss: 0.156711\n",
      "Epoch: 19 \tTraining Loss: 0.592169 \tValidation Loss: 0.152873\n",
      "Epoch: 20 \tTraining Loss: 0.604129 \tValidation Loss: 0.154425\n",
      "Epoch: 1 \tTraining Loss: 0.597301 \tValidation Loss: 0.154507\n",
      "Validation loss decreased (inf --> 0.154507).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.603143 \tValidation Loss: 0.147926\n",
      "Validation loss decreased (0.154507 --> 0.147926).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.596763 \tValidation Loss: 0.148091\n",
      "Epoch: 4 \tTraining Loss: 0.593854 \tValidation Loss: 0.152825\n",
      "Epoch: 5 \tTraining Loss: 0.595895 \tValidation Loss: 0.153652\n",
      "Epoch: 6 \tTraining Loss: 0.597575 \tValidation Loss: 0.152762\n",
      "Epoch: 7 \tTraining Loss: 0.598655 \tValidation Loss: 0.146117\n",
      "Validation loss decreased (0.147926 --> 0.146117).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.606855 \tValidation Loss: 0.149588\n",
      "Epoch: 9 \tTraining Loss: 0.593047 \tValidation Loss: 0.164618\n",
      "Epoch: 10 \tTraining Loss: 0.605157 \tValidation Loss: 0.146074\n",
      "Validation loss decreased (0.146117 --> 0.146074).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.592503 \tValidation Loss: 0.151204\n",
      "Epoch: 12 \tTraining Loss: 0.597726 \tValidation Loss: 0.153325\n",
      "Epoch: 13 \tTraining Loss: 0.601072 \tValidation Loss: 0.145463\n",
      "Validation loss decreased (0.146074 --> 0.145463).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.597204 \tValidation Loss: 0.141559\n",
      "Validation loss decreased (0.145463 --> 0.141559).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.598513 \tValidation Loss: 0.148553\n",
      "Epoch: 16 \tTraining Loss: 0.597369 \tValidation Loss: 0.148792\n",
      "Epoch: 17 \tTraining Loss: 0.604894 \tValidation Loss: 0.148356\n",
      "Epoch: 18 \tTraining Loss: 0.594132 \tValidation Loss: 0.158058\n",
      "Epoch: 19 \tTraining Loss: 0.596805 \tValidation Loss: 0.142342\n",
      "Epoch: 20 \tTraining Loss: 0.595746 \tValidation Loss: 0.147079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#--------------------------------pca--------------------------\n",
    "weights_list = []\n",
    "weights_list1 = []\n",
    "train_losslist1 = []\n",
    "for i in range(8):\n",
    "    n_epochs = [*range(20)]\n",
    "    valid_loss_min = np.Inf \n",
    "    plt.figure()\n",
    "    for epoch in range(1, len(n_epochs)+1):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        model1.train()\n",
    "        for data, target in train_loader:\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model1(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "        model1.eval()\n",
    "        #weights = list(model1.parameters())\n",
    "        #print(weights)\n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            weights = []\n",
    "            weights1=[]\n",
    "            for name, param in model1.named_parameters():\n",
    "                if \"weight\" in name:\n",
    "                    weights.append(param.data.cpu().numpy().flatten())\n",
    "            weights = np.concatenate(weights)\n",
    "            weights_list.append(weights)\n",
    "            weights1.append(model1.fc1.weight.data.cpu().numpy().flatten())\n",
    "            weights1 = np.concatenate(weights1)\n",
    "            weights_list1.append(weights1)\n",
    "            \n",
    "        \n",
    "        for data, target in valid_loader:\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model1(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        train_losslist1.append(train_loss)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "            torch.save(model1.state_dict(), 'model_cifar.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8c15fc2-bc13-4aa9-a90d-8b0771d044f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = ['red', 'blue', 'yellow', 'green', 'orange', 'cyan','black']\n",
    "pca = PCA(n_components=2)\n",
    "weights_2d = pca.fit_transform(weights_list)\n",
    "# Plot pca1 vs pca2 on a graph\n",
    "plt.scatter(weights_2d[:, 0], weights_2d[:, 1])\n",
    "plt.title('whole model')\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.savefig('whole model weights.png')\n",
    "plt.show()\n",
    "\n",
    "pca1 = PCA(n_components=2)\n",
    "weights_2d1 = pca1.fit_transform(weights_list1)\n",
    "plt.scatter(weights_2d1[:, 0], weights_2d1[:, 1])\n",
    "plt.title('one layer')\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.savefig('one layer.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
